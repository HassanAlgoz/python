---
og:title: sentiment_analysis_solution
---

# Ø§Ù„Ø­Ù„ {.unnumbered}

**ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±** (Sentiment Analysis) Ù‡Ùˆ ÙØ±Ø¹ Ù…Ù† ÙØ±ÙˆØ¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (NLP) Ø§Ù„Ù…Ù†Ø¯Ø±Ø¬Ø© ØªØ­Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (AI) ÙŠÙ‡Ø¯Ù Ø¥Ù„Ù‰ ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© Ù…Ù† Ø¬Ù‡Ø© Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø¹Ø¨Ø± Ø¹Ù†Ù‡Ø§: Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© ðŸ˜€ Ø£Ùˆ Ø³Ù„Ø¨ÙŠØ© ðŸ˜¡ Ø£Ùˆ Ù…Ø­Ø§ÙŠØ¯Ø© ðŸ˜ï¸.

ÙˆØºØ§Ù„Ø¨Ø§Ù‹ Ù…Ø§ ÙŠØ·Ø¨Ù‘ÙŽÙ‚ Ù„Ø£ØªÙ…ØªØ© Ù…Ø¹Ø±ÙØ© **Ø§Ù„Ø±Ø£ÙŠ Ø§Ù„Ø¹Ø§Ù…** Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø± ÙÙŠ Ø§Ø³ØªØ·Ù„Ø§Ø¹Ø§Øª Ø§Ù„Ø±Ø£ÙŠØŒ Ø£Ùˆ Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø¹Ù„Ù‰ ÙˆØ³Ø§Ø¦Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„.

Ù…Ù‡Ù…ØªÙ†Ø§: **Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø­ØµØ§Ø¦ÙŠ Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ø¦Ù… ÙƒÙ„Ù…Ø§Øª Ù…ØµÙ†Ù‘ÙŽÙØ© Ù…ÙØ³Ø¨Ù‚Ù‹Ø§**.

Ù„Ø¯ÙŠÙ†Ø§ Ø«Ù„Ø§Ø«Ø© Ù…Ù„ÙØ§Øª:

1. Ø§Ù„Ø£ÙˆÙ„ ÙŠØ­ÙˆÙŠ ØªØºØ±ÙŠØ¯Ø§Øª: [tweets.txt](../../datasets/tweets/tweets.txt)
2. Ø§Ù„Ø«Ø§Ù†ÙŠ ÙŠØ­ÙˆÙŠ ÙƒÙ„Ù…Ø§Øª Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ©: [words_positive.txt](../../datasets/tweets/words_positive.txt)
3. Ø§Ù„Ø«Ø§Ù„Ø« ÙŠØ­ÙˆÙŠ ÙƒÙ„Ù…Ø§Øª Ø³Ù„Ø¨ÙŠØ©: [words_negative.txt](../../datasets/tweets/words_negative.txt)

Ù†Ø±ÙŠØ¯ ØªØµÙ†ÙŠÙ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© ÙˆØ§Ù„Ø³Ù„Ø¨ÙŠØ© ÙÙŠÙ‡Ø§.

```{python}
from pathlib import Path

data_dir = Path('../../datasets/tweets')
```


Ø¨Ø¹Ø¯ Ø§Ù„Ù†Ø¸Ø± ÙÙŠ Ø´ÙƒÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª. ÙŠØªØ¨ÙŠÙ† Ù„Ù†Ø§ Ø£Ù† Ø§Ù„Ø³Ø·Ø± Ø§Ù„ÙˆØ§Ø­Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ "Ø´ÙŠØ¡" ÙˆØ§Ø­Ø¯. ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠ Ø³Ù†Ù‚Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ ÙƒÙ„ Ø³Ø·Ø±.

ÙˆÙ†Ù„Ø§Ø­Ø¸ Ø£ÙŠØ¶Ù‹Ø§ ÙˆØ¬ÙˆØ¯ Ø£Ø³Ø·Ø± Ø®Ø§ÙˆÙŠØ©ØŒ ÙŠØ¬Ø¨ Ø§Ù„ØªØ®Ù„Øµ Ù…Ù†Ù‡Ø§.

```{python}
def read_lines(file_path: Path) -> list[str]:
    """skips empty lines and converts to lowercase"""
    result = []
    with open(file_path, 'r') as file:
        for line in file:
            x = line.strip()
            if len(x) > 0:
                x = x.lower()
                result.append(x)
    return result
```

Ù†Ø³ØªØ¯Ø¹ÙŠ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø«Ù„Ø§Ø«:

```{python}
tweets = read_lines(data_dir / 'tweets.txt')
positive_words = read_lines(data_dir / 'words_positive.txt')
negative_words = read_lines(data_dir / 'words_negative.txt') 
```

```{python}
for i, tweet in enumerate(tweets):
    print(i, tweet)
```

```{python}
for p in positive_words:
    print(p)
```

```{python}
for n in negative_words:
    print(n)
```

Ø§Ù„Ø¢Ù† Ù†Ù‚ÙˆÙ… Ø¨ØªØµÙ†ÙŠÙ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª:

```{python}
def classify(text: str) -> (int, int):
    """Returns the number of positive and negative words in the text"""
    
    positive_count = 0
    for word in positive_words:
        if word in text:
            positive_count += 1
    
    negative_count = 0
    for word in negative_words:
        if word in text:
            negative_count += 1
    
    return positive_count, negative_count

assert classify('Ø£Ù†Ø§ Ø³Ø¹ÙŠØ¯') == (1, 0)
assert classify('Ø£Ù†Ø§ Ø­Ø²ÙŠÙ†') == (0, 1)
assert classify('Ø³Ø¹ÙŠØ¯ Ø­Ø²ÙŠÙ† Ø§Ù„ÙŠÙˆÙ…') == (1, 1)
assert classify('Ø§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰ Ø§Ù„Ø¯ÙƒØ§Ù†') == (0, 0)
```

Ù†Ø³ØªØ¯Ø¹ÙŠ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§ØªØŒ ÙˆÙ†ÙØ±Ø² Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø«Ù„Ø§Ø«Ø© Ù‚ÙˆØ§Ø¦Ù…:

```{python}
positive_tweets = []
negative_tweets = []
neutral_tweets = []
for tweet in tweets:
    pos, neg = classify(tweet)
    score = pos - neg
    print(f'-{neg} +{pos} = {score:+}')
    if score > 0:
        positive_tweets.append((tweet, score))
    elif score < 0:
        negative_tweets.append((tweet, score))
    else:
        neutral_tweets.append((tweet, score))
```

Ù†Ø¹Ø±Ø¶ Ø§Ù„ØªØºØ±ÙŠØ¯Ø§Øª Ø¨Ø­Ø³Ø¨ Ø§Ù„ØªØµÙ†ÙŠÙ Ù…Ø±ØªØ¨Ø© Ø¨Ù‚ÙˆØ© Ø§Ù„ØªØµÙ†ÙŠÙ Ù…Ù† Ø§Ù„Ø£Ø¹Ù„Ù‰ Ø¥Ù„Ù‰ Ø§Ù„Ø£Ø³ÙÙ„:

```{python}
print('positive_tweets:')
for tweet, score in sorted(positive_tweets, key=lambda x: x[1], reverse=True):
    print(f'{score:+} {tweet}')
```

```{python}
print('negative_tweets:')
for tweet, score in sorted(negative_tweets, key=lambda x: x[1]):
    print(f'{score:+} {tweet}')
```

```{python}
print('neutral_tweets:')
for tweet, score in neutral_tweets:
    print(f'{score} {tweet}')
```
